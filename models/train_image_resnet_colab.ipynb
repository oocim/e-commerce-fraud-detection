{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb0be80",
   "metadata": {},
   "source": [
    "# Fraud Detection — Fine-tune ResNet-50 on Product Images (Colab)\n",
    "\n",
    "This notebook:\n",
    "1. Uploads `image_dataset.csv` (contains `product_id`, `fraud_label`, `image_url`)\n",
    "2. Downloads product images from URLs\n",
    "3. Fine-tunes a pretrained **ResNet-50** for binary fraud classification\n",
    "4. Handles class imbalance with weighted loss\n",
    "5. Reports evaluation metrics on a stratified test split\n",
    "\n",
    "**Make sure to select GPU runtime:** Runtime → Change runtime type → T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab-compatible — use Colab's pre-installed torch/pandas/numpy)\n",
    "!pip -q install torchvision scikit-learn Pillow requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77cc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14368a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_DIR = Path('./downloaded_images')\n",
    "MODEL_SAVE_PATH = Path('./resnet_fraud_model')\n",
    "\n",
    "IMAGE_DIR.mkdir(exist_ok=True)\n",
    "MODEL_SAVE_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload image_dataset.csv\n",
    "if IN_COLAB:\n",
    "    print('Upload image_dataset.csv ...')\n",
    "    uploaded = files.upload()\n",
    "    if 'image_dataset.csv' not in uploaded:\n",
    "        raise ValueError(f'Expected image_dataset.csv. Uploaded: {list(uploaded.keys())}')\n",
    "    df = pd.read_csv(io.BytesIO(uploaded['image_dataset.csv']))\n",
    "else:\n",
    "    df = pd.read_csv('processed_data/image_dataset.csv')\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Fraud distribution:\\n{df[\"fraud_label\"].value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images from URLs (parallel, with retry)\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "}\n",
    "\n",
    "def download_image(row):\n",
    "    \"\"\"Download a single image. Returns (product_id, success).\"\"\"\n",
    "    pid = str(row['product_id']).zfill(6)\n",
    "    url = row['image_url']\n",
    "    save_path = IMAGE_DIR / f'{pid}.jpg'\n",
    "    if save_path.exists():\n",
    "        return pid, True\n",
    "    try:\n",
    "        resp = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        resp.raise_for_status()\n",
    "        img = Image.open(io.BytesIO(resp.content)).convert('RGB')\n",
    "        img.save(save_path, 'JPEG')\n",
    "        return pid, True\n",
    "    except Exception:\n",
    "        return pid, False\n",
    "\n",
    "print(f'Downloading {len(df)} images (skipping already downloaded) ...')\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    futures = {executor.submit(download_image, row): row for _, row in df.iterrows()}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        results.append(future.result())\n",
    "\n",
    "success_ids = {pid for pid, ok in results if ok}\n",
    "failed_ids  = {pid for pid, ok in results if not ok}\n",
    "print(f'\\nDownloaded: {len(success_ids)} | Failed: {len(failed_ids)}')\n",
    "\n",
    "# Keep only rows with successfully downloaded images\n",
    "df['pid_str'] = df['product_id'].apply(lambda x: str(x).zfill(6))\n",
    "df = df[df['pid_str'].isin(success_ids)].reset_index(drop=True)\n",
    "print(f'Usable samples: {len(df)}')\n",
    "print(f'Fraud distribution after filtering:\\n{df[\"fraud_label\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da95f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split (stratified)\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=SEED, stratify=df['fraud_label']\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df  = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f'Train: {len(train_df)} | Test: {len(test_df)}')\n",
    "print(f'Train fraud ratio: {train_df[\"fraud_label\"].mean():.4f}')\n",
    "print(f'Test  fraud ratio: {test_df[\"fraud_label\"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms & Dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class FraudImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform):\n",
    "        self.df = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        pid = str(row['product_id']).zfill(6)\n",
    "        img_path = self.img_dir / f'{pid}.jpg'\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor(row['fraud_label'], dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = FraudImageDataset(train_df, IMAGE_DIR, train_transform)\n",
    "test_dataset  = FraudImageDataset(test_df,  IMAGE_DIR, test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)} | Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a98a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: ResNet-50 (pretrained) with custom head\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Freeze early layers, fine-tune layer4 + fc\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Replace classifier\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 2),\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Class weights for imbalance\n",
    "n_neg = (train_df['fraud_label'] == 0).sum()\n",
    "n_pos = (train_df['fraud_label'] == 1).sum()\n",
    "class_weights = torch.tensor([1.0, n_neg / n_pos], dtype=torch.float).to(device)\n",
    "print(f'Class weights: not-fraud=1.00, fraud={n_neg / n_pos:.2f}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LR, weight_decay=1e-4\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f'Trainable params: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_f1 = 0.0\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_f1': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    val_loss = val_loss / len(test_dataset)\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    val_f1  = f1_score(all_labels, all_preds)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    marker = ''\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH / 'best_resnet50.pth')\n",
    "        marker = ' ← saved best'\n",
    "\n",
    "    print(f'Epoch {epoch}/{EPOCHS}  '\n",
    "          f'train_loss={train_loss:.4f}  '\n",
    "          f'val_loss={val_loss:.4f}  '\n",
    "          f'val_acc={val_acc:.4f}  '\n",
    "          f'val_f1={val_f1:.4f}{marker}')\n",
    "\n",
    "print(f'\\nBest validation F1: {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6db5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model & final evaluation\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH / 'best_resnet50.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels, all_probs = [], [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_true = np.array(all_labels)\n",
    "y_pred = np.array(all_preds)\n",
    "y_prob = np.array(all_probs)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1  = f1_score(y_true, y_pred)\n",
    "roc = roc_auc_score(y_true, y_prob)\n",
    "ap  = average_precision_score(y_true, y_prob)\n",
    "\n",
    "print('=' * 60)\n",
    "print('  Final Evaluation — ResNet-50')\n",
    "print('=' * 60)\n",
    "print(f'Accuracy          : {acc:.4f}')\n",
    "print(f'F1 Score (fraud)  : {f1:.4f}')\n",
    "print(f'ROC-AUC           : {roc:.4f}')\n",
    "print(f'Avg Precision (PR): {ap:.4f}\\n')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=['Not Fraud', 'Fraud']))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test-set predictions for ensemble\n",
    "image_preds_df = pd.DataFrame({\n",
    "    'product_id': test_df['product_id'].values,\n",
    "    'fraud_label': y_true,\n",
    "    'image_fraud_proba': y_prob,\n",
    "    'image_pred': y_pred,\n",
    "})\n",
    "image_preds_df.to_csv('image_test_predictions.csv', index=False)\n",
    "print(f'Saved image_test_predictions.csv  ({len(image_preds_df)} rows)')\n",
    "print(image_preds_df.head())\n",
    "\n",
    "# Download for local ensemble\n",
    "if IN_COLAB:\n",
    "    files.download('image_test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'],   label='Val Loss')\n",
    "axes[0].set_title('Loss'); axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['val_acc'])\n",
    "axes[1].set_title('Validation Accuracy')\n",
    "\n",
    "axes[2].plot(history['val_f1'])\n",
    "axes[2].set_title('Validation F1 (Fraud)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Epoch')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b699a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "print(f'Best model saved to: {(MODEL_SAVE_PATH / \"best_resnet50.pth\").resolve()}')\n",
    "\n",
    "# Optional: download the model file in Colab\n",
    "if IN_COLAB:\n",
    "    files.download(str(MODEL_SAVE_PATH / 'best_resnet50.pth'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
